# -*- coding: utf-8 -*-
"""CV_M20MA008Assignment03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17pRyk8B9Rs71Un2ESY76092SyVANUscB

# **Important Liberaries**
"""

!pip install imutils
#!pip install opencv-contrib-python==4.4.0.44

!pip install pyimagesearch

import numpy as np
import imutils
import cv2
#from pyimagesearch.panorama import Stitcher
import argparse


import matplotlib.pyplot as plt
import imageio

from google.colab.patches import cv2_imshow

import os

# Import required modules

import glob

from PIL import Image, ImageDraw
from math import sqrt, pi, cos, sin
#from canny import canny_edge_detector
from collections import defaultdict



"""# **Question 1 : Object Recognition**

Use the CIFAR10 dataset for this question.Extract the following features from the images and train a 2-layer neural network for classification.

 *  Local Binary Patterns (LBP) (To be done from scratch) (20 marks
 * Scale-Invariant feature Transform (SIFT) (10 marks)
 * Histogram of gradients (HOG) (10 marks)
 * Deep features (Use AlexNet pre-trained on Imagenet to extract the 4096-dimensional feature vector) (10 marks)

* Deep features (Use ResNet18 pre-trained on Imagenet to extract feature vector) (10
marks)

##Local Binary Patterns (LBP) (To be done from scratch)
"""

import numpy as np

from keras.datasets import cifar10
from keras.utils.np_utils import to_categorical   


(X_train, y_train), (X_test, y_test) = cifar10.load_data()

cv2_imshow(X_train[1])

X_train.shape

import matplotlib.pyplot as plt

cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
print('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]])) 
print('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))

f, axarr = plt.subplots(1, 5)
f.set_size_inches(16, 6)

for i in range(5):
    img = X_train[i]
    axarr[i].imshow(img)
plt.show()

import math
def LocalBinaryPattern(image):
    image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    row=image.shape[0]
    col=image.shape[1]
    #row=3
    #col=3

    filRow=3
    filCol=3
    #imageNew=[]
    for i in range(0,row-filRow):
        #print("\n---------------------------------------------------------------------------------------------------------------------------- loop no : ",i)
        for j in range(0,col-filCol):
            #print("\n Column loop no : ",j)
            #print("\n")
            MidValue=image[i+1,j+1]       # Get the mid pixel value
            #print("mid value is : ",MidValue)
            k=i
            m=i+filRow
            l=j
            n=j+filCol

            binary=0
            sum=0
            for ii in range(l, n):
                if (image[k][ii]>MidValue):
                    sum=sum +  math.pow(2,binary)
                    #print("sum",sum)
                    binary=binary+1
                else:
                    binary=binary+1
                    #print("binary",binary)

 
            k += 1
            for ii in range(k, m):
                if (image[ii][n - 1]>MidValue):
                    sum=sum +  math.pow(2,binary)
                    #print("sum",sum)
                    binary=binary+1
                else:
                    binary=binary+1
                    #print("binary",binary)
 
            n -= 1

            if (k < m):
 
                for ii in range(n - 1, (l - 1), -1):
                   # print(image[m - 1][ii], end=" ")
                    if (image[m - 1][ii]>MidValue):
                        sum=sum + math.pow(2,binary)
                        #print("sum",sum)
                        binary=binary+1
                    else:
                        binary=binary+1
                        #print("binary",binary)
 
                m -= 1

            if (l < n):
                for ii in range(m - 1, k - 1, -1):
                    #print(image[ii][l], end=" ")
                    if (image[ii][l]>MidValue):
                        sum=sum +  math.pow(2,binary)
                        #print("sum",sum)
                        binary=binary+1
                    else:
                        binary=binary+1
                        #print("binary",binary)

 
                l += 1
 
            #input()
            image[i+1,j+1]=sum
        #finput[i+1,j+1]=temp[int(len(temp)/2)]

    return image

newImage=LocalBinaryPattern(X_train[1])
X_train.shape[0]
x_train=[]
for i in range(X_train.shape[0]):
    
    x_train.append(LocalBinaryPattern(X_train[i]))
x_train=np.array(x_train)

#newImage=LocalBinaryPattern(X_train[1])
#X_train.shape[0]
x_test=[]
for i in range(X_test.shape[0]):
    
    x_test.append(LocalBinaryPattern(X_test[i]))
    #print(i)
x_test=np.array(x_test)

import matplotlib.pyplot as plt

cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
print('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]])) 
print('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))

f, axarr = plt.subplots(1, 5)
f.set_size_inches(16, 6)

for i in range(5):
    img = x_train[i]
    axarr[i].imshow(img)
    plt.show()

x_train.shape

# Reshaping
train_images=x_train.reshape((-1,1024))
test_images=x_test.reshape((-1,1024))

y_train

train_images.shape

import torch
import torchvision
from torch.utils.data import Dataset, DataLoader
import numpy as np
import math

# gradient computation etc. not efficient for whole data set
# -> divide dataset into small batches

'''
# training loop
for epoch in range(num_epochs):
    # loop over all batches
    for i in range(total_batches):
        batch_x, batch_y = ...
'''

# epoch = one forward and backward pass of ALL training samples
# batch_size = number of training samples used in one forward/backward pass
# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes
# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch

# --> DataLoader can do the batch computation for us

# Implement a custom Dataset:
# inherit Dataset
# implement __init__ , __getitem__ , and __len__

class WineDataset(Dataset):

    def __init__(self,xTrain,yTrain):
        # Initialize data, download, etc.
        # read with numpy or pandas
        #xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)
        xy=xTrain
        self.n_samples = xy.shape[0]

        # here the first column is the class label, the rest are the features
        self.x_data = torch.from_numpy(xTrain) # size [n_samples, n_features]
        self.y_data = torch.from_numpy(yTrain) # size [n_samples, 1]

    # support indexing such that dataset[i] can be used to get i-th sample
    def __getitem__(self, index):
        return self.x_data[index], self.y_data[index]

    # we can call len(dataset) to return the size
    def __len__(self):
        return self.n_samples

# create dataset
dataset = WineDataset(train_images,y_train)

# get first sample and unpack
first_data = dataset[0]
features, labels = first_data
print(features, labels)

# Load whole dataset with DataLoader
# shuffle: shuffle data, good for training
# num_workers: faster loading with multiple subprocesses
# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!
train_loader = DataLoader(dataset=dataset,
                          batch_size=100,
                          shuffle=True,
                          num_workers=2)

# convert to an iterator and look at one random sample
dataiter = iter(train_loader)
data = dataiter.next()
features, labels = data
#print(features, labels)

# Here we create our simple neural network. For more details here we are subclassing and
# inheriting from nn.Module, this is the most general way to create your networks and
# allows for more flexibility. I encourage you to also check out nn.Sequential which
# would be easier to use in this scenario but I wanted to show you something that
# "always" works.



# Imports
import torch
import torchvision # torch package for vision related things
import torch.nn.functional as F  # Parameterless functions, like (some) activation functions
import torchvision.datasets as datasets  # Standard datasets
import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation
from torch import optim  # For optimizers like SGD, Adam, etc.
from torch import nn  # All neural network modules
from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.
from tqdm import tqdm  # For nice progress bar!


class NN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(NN, self).__init__()
        # Our first linear layer take input_size, in this case 784 nodes to 50
        # and our second linear layer takes 50 to the num_classes we have, in
        # this case 10.
        self.fc1 = nn.Linear(input_size, 120)
        self.fc2 = nn.Linear(120, num_classes)

    def forward(self, x):
        """
        x here is the mnist images and we run it through fc1, fc2 that we created above.
        we also add a ReLU activation function in between and for that (since it has no parameters)
        I recommend using nn.functional (F)
        """

        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def check_accuracy(loader, model):
    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)
            x = x.reshape(x.shape[0], -1)
            x=x.to(torch.float)
            y=torch.reshape(y, (-1,))
            y=y.to(torch.long)

            scores = model(x)
            _, predictions = scores.max(1)
            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)

    model.train()
    return num_correct/num_samples

# Set device cuda for GPU if it's available otherwise run on the CPU
#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Hyperparameters of our neural network which depends on the dataset, and
# also just experimenting to see what works well (learning rate for example).
input_size = 1024
num_classes = 10
num_epochs = 20
batch_size = 100
learning_rate = 0.1

# Load Training and Test data
#train_dataset = datasets.MNIST(root="dataset/", train=True, transform=transforms.ToTensor(), download=True)
#test_dataset = datasets.MNIST(root="dataset/", train=False, transform=transforms.ToTensor(), download=True)
#train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
#test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)

#Initialize network
model = NN(input_size=input_size, num_classes=num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
n_total_steps = len(train_loader)
# Train Network
for epoch in range(num_epochs):
    for i, (data, targets) in enumerate(train_loader):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)
        #print("\n target size",targets.shape)
        #input()

        # Get to correct shape
       # data = data.reshape(data.shape[0], -1)

        # forward
        #print(data)
        b=torch.tensor(255)
        data=data.to(torch.float)
        #data=torch.div(data, b, name=None)
        #print(data)
        #input()
        scores = model(data)
        #print(scores.shape)
        #print(targets.shape)
        targets=torch.reshape(targets, (-1,))
        targets=targets.to(torch.long)
        loss = criterion(scores, targets)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer.step()

        if (i+1) % 500== 0:
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')
    #print(epoch)
    #print("-----------------------------------------------------------")
# Check accuracy on training & test to see how good our model

print(f"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}")
print(f"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}")

ClassAccuracy(model,batch_size,test_loader)

"""##Scale-Invariant feature Transform (SIFT)

##Histogram of gradients (HOG)
"""

import numpy as np

from keras.datasets import cifar10
from keras.utils.np_utils import to_categorical   


(X_train, y_train), (X_test, y_test) = cifar10.load_data()
X_train.shape

#importing required libraries
from skimage.io import imread
from skimage.transform import resize
from skimage.feature import hog
from skimage import exposure
import matplotlib.pyplot as plt

cv2_imshow(X_train[0])
#hog = cv2.HOGDescriptor()
#im = cv2.imread(sample)
#h = hog.compute(X_train[2])
fd, hog_image = hog(X_train[4], orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, multichannel=True)
plt.axis("off")
plt.imshow(hog_image, cmap="gray")

#newImage=LocalBinaryPattern(X_train[1])
X_train.shape[0]
x_train=[]
for i in range(X_train.shape[0]):
    fd, hog_image = hog(X_train[i], orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, multichannel=True)
    x_train.append(hog_image)
x_train=np.array(x_train)

#newImage=LocalBinaryPattern(X_train[1])
#X_train.shape[0]
x_test=[]
for i in range(X_test.shape[0]):
    fd, hog_image =(hog(X_test[i], orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, multichannel=True))
    x_test.append(hog_image)
   # x_test.append)
    #print(i)
x_test=np.array(x_test)

x_train=[]
for i in X_train:

#Initialize network
model = NN(input_size=input_size, num_classes=num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
n_total_steps = len(train_loader)
# Train Network
for epoch in range(num_epochs):
    for i, (data, targets) in enumerate(train_loader):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)
        #print("\n target size",targets.shape)
        #input()

        # Get to correct shape
       # data = data.reshape(data.shape[0], -1)

        # forward
        #print(data)
        b=torch.tensor(255)
        data=data.to(torch.float)
        #data=torch.div(data, b, name=None)
        #print(data)
        #input()
        scores = model(data)
        #print(scores.shape)
        #print(targets.shape)
        targets=torch.reshape(targets, (-1,))
        targets=targets.to(torch.long)
        loss = criterion(scores, targets)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer.step()

        if (i+1) % 500== 0:
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')
    #print(epoch)
    #print("-----------------------------------------------------------")
# Check accuracy on training & test to see how good our model

#Initialize network
model = NN(input_size=input_size, num_classes=num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
n_total_steps = len(train_loader)
# Train Network
for epoch in range(num_epochs):
    for i, (data, targets) in enumerate(train_loader):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)
        #print("\n target size",targets.shape)
        #input()

        # Get to correct shape
       # data = data.reshape(data.shape[0], -1)

        # forward
        #print(data)
        b=torch.tensor(255)
        data=data.to(torch.float)
        #data=torch.div(data, b, name=None)
        #print(data)
        #input()
        scores = model(data)
        #print(scores.shape)
        #print(targets.shape)
        targets=torch.reshape(targets, (-1,))
        targets=targets.to(torch.long)
        loss = criterion(scores, targets)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer.step()

        if (i+1) % 500== 0:
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')
    #print(epoch)
    #print("-----------------------------------------------------------")
# Check accuracy on training & test to see how good our model

"""##Deep features (Use AlexNet pre-trained on Imagenet to extract the 4096-dimensionalfeature vector)"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy

transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

#Downloading training data
train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True, num_workers=4)

#Downloading test data
test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

testloader = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=False, num_workers=4)

#Class labels

classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')

#Now using the ResNet
resNET50 = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)

#Model description
resNET50.eval()

for param in resNET50.parameters():
    param.requires_grad = True
#Updating the second classifier
resNET50.fc = nn.Linear(2048, 2048)

resNET50.eval()

#Instantiating CUDA device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

#Verifying CUDA
print(device)

#Move the input and resNET50 to GPU for speed if available
resNET50.to(device)



# Here we create our simple neural network. For more details here we are subclassing and
# inheriting from nn.Module, this is the most general way to create your networks and
# allows for more flexibility. I encourage you to also check out nn.Sequential which
# would be easier to use in this scenario but I wanted to show you something that
# "always" works.
class NN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(NN, self).__init__()
        # Our first linear layer take input_size, in this case 784 nodes to 50
        # and our second linear layer takes 50 to the num_classes we have, in
        # this case 10.
        self.fc1 = nn.Linear(input_size, 120)
        self.fc2 = nn.Linear(120, num_classes)

    def forward(self, x):
        """
        x here is the mnist images and we run it through fc1, fc2 that we created above.
        we also add a ReLU activation function in between and for that (since it has no parameters)
        I recommend using nn.functional (F)
        """

        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def check_accuracy(loader, model):
    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)
            x = x.reshape(x.shape[0], -1)
            x=x.to(torch.float)
            y=torch.reshape(y, (-1,))
            y=y.to(torch.long)

            scores = model(x)
            _, predictions = scores.max(1)
            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)

    model.train()
    return num_correct/num_samples

# Set device cuda for GPU if it's available otherwise run on the CPU
#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Hyperparameters of our neural network which depends on the dataset, and
# also just experimenting to see what works well (learning rate for example).
input_size = 2048
num_classes = 10
num_epochs = 20
batch_size = 10
learning_rate = 0.1

# Load Training and Test data
#train_dataset = datasets.MNIST(root="dataset/", train=True, transform=transforms.ToTensor(), download=True)
#test_dataset = datasets.MNIST(root="dataset/", train=False, transform=transforms.ToTensor(), download=True)
#train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
#test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)

#Initialize network
model = NN(input_size=input_size, num_classes=num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
n_total_steps = len(trainloader)
# Train Network
for epoch in range(num_epochs):
    for i, (data, targets) in enumerate(trainloader):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)
        #print("\n target size",targets.shape)
        #input()

        # Get to correct shape
       # data = data.reshape(data.shape[0], -1)

        # forward
        #print(data)
        b=torch.tensor(255)
        data=data.to(torch.float)
        #data=torch.div(data, b, name=None)
        #print(data)
        #input()
        output = resNET50(data)
        scores = model(output)
        #print(scores.shape)
        #print(targets.shape)
        targets=torch.reshape(targets, (-1,))
        targets=targets.to(torch.long)
        loss = criterion(scores, targets)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer.step()

        if (i+1) % 500== 0:
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')
    #print(epoch)
    #print("-----------------------------------------------------------")
# Check accuracy on training & test to see how good our model

#Classwise Accuracy
#Multionfusion Matrix
yprelast=[]
with torch.no_grad():
    n_correct = 0
    n_samples = 0
    n_class_correct = [0 for i in range(10)]
    n_class_samples = [0 for i in range(10)]
    for images, labels in testloader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = resNET50(images)
        # max returns (value ,index)
        _, predicted = torch.max(outputs, 1)
        temp=predicted.cpu().detach().numpy()
        for kk in temp:
            yprelast.append(kk)
        n_samples += labels.size(0)
        n_correct += (predicted == labels).sum().item()
        #print(labels.shape)
        #print(images.shape)
        #input()
        for i in range(100):
            label = labels[i]
            pred = predicted[i]
            if (label == pred):
                n_class_correct[label] += 1
            n_class_samples[label] += 1

    acc = 100.0 * n_correct / n_samples
    print(f'Accuracy of the network: {acc} %')

    for i in range(10):
        acc = 100.0 * n_class_correct[i] / n_class_samples[i]
        print(f'Accuracy of {classes[i]}: {acc} %')

"""##Deep features (Use ResNet18 pre-trained on Imagenet to extract feature vector)"""



transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

#Downloading training data
train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True, num_workers=4)

#Downloading test data
test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

testloader = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=False, num_workers=4)

#Class labels

classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')

#Now using the ResNet
resNET50 = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)

#Model description
resNET50.eval()

for param in resNET50.parameters():
    param.requires_grad = True
#Updating the second classifier
resNET50.fc = nn.Linear(1000, 4096)

resNET50.eval()

#Instantiating CUDA device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

#Verifying CUDA
print(device)

#Move the input and resNET50 to GPU for speed if available
resNET50.to(device)
resNET50.fc.to(device)



# Here we create our simple neural network. For more details here we are subclassing and
# inheriting from nn.Module, this is the most general way to create your networks and
# allows for more flexibility. I encourage you to also check out nn.Sequential which
# would be easier to use in this scenario but I wanted to show you something that
# "always" works.
class NN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(NN, self).__init__()
        # Our first linear layer take input_size, in this case 784 nodes to 50
        # and our second linear layer takes 50 to the num_classes we have, in
        # this case 10.
        self.fc1 = nn.Linear(input_size, 120)
        self.fc2 = nn.Linear(120, num_classes)

    def forward(self, x):
        """
        x here is the mnist images and we run it through fc1, fc2 that we created above.
        we also add a ReLU activation function in between and for that (since it has no parameters)
        I recommend using nn.functional (F)
        """

        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def check_accuracy(loader, model):
    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)
            x = x.reshape(x.shape[0], -1)
            x=x.to(torch.float)
            y=torch.reshape(y, (-1,))
            y=y.to(torch.long)

            scores = model(x)
            _, predictions = scores.max(1)
            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)

    model.train()
    return num_correct/num_samples

# Set device cuda for GPU if it's available otherwise run on the CPU
#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Hyperparameters of our neural network which depends on the dataset, and
# also just experimenting to see what works well (learning rate for example).
input_size = 4096
num_classes = 10
num_epochs = 20
batch_size = 10
learning_rate = 0.1

# Load Training and Test data
#train_dataset = datasets.MNIST(root="dataset/", train=True, transform=transforms.ToTensor(), download=True)
#test_dataset = datasets.MNIST(root="dataset/", train=False, transform=transforms.ToTensor(), download=True)
#train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
#test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)

num_epochs=2
n_total_steps = len(trainloader)
for epoch in range(num_epochs):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)
#Initialize network
model = NN(input_size=input_size, num_classes=num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
n_total_steps = len(trainloader)
# Train Network
for epoch in range(num_epochs):
    for i, (data, targets) in enumerate(trainloader):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)
        #print("\n target size",targets.shape)
        #input()

        # Get to correct shape
       # data = data.reshape(data.shape[0], -1)

        # forward
        #print(data)
        b=torch.tensor(255)
        data=data.to(torch.float)
        #data=torch.div(data, b, name=None)
        #print(data)
        #input()
        output = resNET50(data)
        #print(output.shape)
        output=resNET50.fc(output)
        scores = model(output)
        #print(scores.shape)
        #print(targets.shape)
        targets=torch.reshape(targets, (-1,))
        targets=targets.to(torch.long)
        loss = criterion(scores, targets)

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer.step()

        if (i+1) % 500== 0:
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')
    #print(epoch)
    #print("-----------------------------------------------------------")
# Check accuracy on training & test to see how good our model


        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        #print(inputs.shape)
        #input()
        output = resNET50(inputs)
        loss = criterion(output, labels)
        loss.backward()
        optimizer.step()

        # print statistics
       # running_loss += loss.item()
        if (i+1) % 50 == 0:
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')

        #if i % 20 == 0:    # print every 2000 mini-batches
          #  print('[%d, %5d] loss: %.3f' %
          #        (epoch + 1, i + 1, running_loss / 2000))
          #  running_loss = 0.0

print('Finished Training of resNet')

#Classwise Accuracy
#Multionfusion Matrix
yprelast=[]
with torch.no_grad():
    n_correct = 0
    n_samples = 0
    n_class_correct = [0 for i in range(10)]
    n_class_samples = [0 for i in range(10)]
    for images, labels in testloader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = resNET50(images)
        # max returns (value ,index)
        _, predicted = torch.max(outputs, 1)
        temp=predicted.cpu().detach().numpy()
        for kk in temp:
            yprelast.append(kk)
        n_samples += labels.size(0)
        n_correct += (predicted == labels).sum().item()
        #print(labels.shape)
        #print(images.shape)
        #input()
        for i in range(100):
            label = labels[i]
            pred = predicted[i]
            if (label == pred):
                n_class_correct[label] += 1
            n_class_samples[label] += 1

    acc = 100.0 * n_correct / n_samples
    print(f'Accuracy of the network: {acc} %')

    for i in range(10):
        acc = 100.0 * n_class_correct[i] / n_class_samples[i]
        print(f'Accuracy of {classes[i]}: {acc} %')

"""#Question 2

## Vilas jonas and Optical FLow
"""

import cv2
 
# Opens the Video file
cap= cv2.VideoCapture('/content/drive/MyDrive/Comuter_Vision/A3/Q4/Q2/r.mp4')
i=0
while(cap.isOpened()):
    ret, frame = cap.read()

    if ret == False:
        break
    cv2.imwrite('kang'+str(i)+'.jpg',frame)
    i+=1
 
cap.release()
cv2.destroyAllWindows()

# Lucas kanade params
lk_params = dict(winSize = (15, 15),
            maxLevel = 4,
            criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

import numpy as np
import cv2

face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')

img = cv2.imread('/content/kang0.jpg')
img=cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

#face_cascade
from google.colab.patches import cv2_imshow

cv2_imshow(img)

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
#eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
faces = face_cascade.detectMultiScale(gray, 1.3, 5)
print(faces)
for (x,y,w,h) in faces:
    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]
    #eyes = eye_cascade.detectMultiScale(roi_gray)
    

cv2_imshow(img)
cv2.waitKey(0)
cv2.destroyAllWindows()

roi_gray

images1 = sorted(glob.glob('/content/*jpg'))
images1

#faces=faces.astype(np.float32)
faces
# params for corner detection
feature_params = dict( maxCorners = 100,
                       qualityLevel = 0.3,
                       minDistance = 7,
                       blockSize = 7 )

p0 = cv2.goodFeaturesToTrack(gray, mask = None,
                             **feature_params)
print(p0.ndim)
print(faces.ndim)
print(p0[1])
faces



l=[]
for i in range(60,238,1):
    for j in range(196,238,1):
        #print(i,j)
        l.append([[i,j]])
ll=np.array(l)
ll=np.array(l)
ll=ll.astype(np.float32)
ll.ndim
ll
p0=ll

# Create some random colors
color = np.random.randint(0,255,(200,3))
color=color[33]
mask = np.zeros_like(img)
# import the module
import sys

# import the module
import sys
  
max_int = sys.maxsize
min_int = sys.maxsize-1
long_int = sys.maxsize+1
  
print("maxint :"+str(max_int)+" - "+str(type(max_int)))
print("maxint - 1 :"+str(max_int)+" - "+str(type(min_int)))
print("maxint + 1 :"+str(max_int)+" - "+str(type(long_int)))

for i in images1:
    if i=='/content/kang0.jpg':
        continue

    img = cv2.imread(i)
    img=cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE)
    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    p1, st, err  = cv2.calcOpticalFlowPyrLK(gray, gray_frame, p0, None, **lk_params)
    
    # Select good points
    if p1 is not None:
        good_new = p1[st==1]
        good_old = p0[st==1]
    # draw the tracks
    max_x = 0
    min_x =sys.maxsize
    max_y = 0
    min_y =sys.maxsize
    for i,(new,old) in enumerate(zip(good_new, good_old)):
        a,b = new.ravel()
        #c,d = old.ravel()
        if (int(a)<=int(min_x)):
            min_x=int(a)
        if (int(a)>=int(max_x)):
            max_x=int(a)
            
        
        if (int(b)<=int(min_y)):
            min_y=int(b)
        if (int(b)>=int(max_y)):
            max_y=int(b)
    min_x+=30
    min_y+=30
    max_x-=50
    max_y-=150
    #    print(a,b)
    #    print(c,d)
    #    mask = cv2.line(mask, (int(a),int(b)),(int(c),int(d)), color.tolist(), 2)
    #    print(mask.shape)
    #    input()

    #    frame = cv2.circle(img,(int(a),int(b)),5,color.tolist(),-1)
   
    print(min_x,min_y,max_x,max_y)
    img = cv2.rectangle(img,(min_x,min_y),(max_x,min_y), color.tolist(),2)
    img = cv2.rectangle(img,(max_x,min_y),(max_x,max_y), color.tolist(),2)
    img = cv2.rectangle(img,(max_x,max_y),(min_x,max_y), color.tolist(),2)
    img = cv2.rectangle(img,(min_x,max_y),(min_x,min_y), color.tolist(),2)

    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
#eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    print(faces)
    for (x,y,w,h) in faces:
        img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]
    #eyes

    #print(frame.shape)
    #print(len(mask))
    #input()
    #img = cv2.add(frame,mask)
    cv2_imshow(img)
    k = cv2.waitKey(30) & 0xff
    if k == 27:
        break
    # Now update the previous frame and previous points
    gray = gray_frame.copy()
    p0 = good_new.reshape(-1,1,2)



"""# Question 3"""



!pip install segmentation-models
!pip install tensorflow==2.1.0
!pip install keras==2.3.1

import glob
import cv2
import os
import numpy as np
from matplotlib import pyplot as plt

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from __future__ import print_function

import os
from skimage.transform import resize
from skimage.io import imsave
import numpy as np
from skimage.segmentation import mark_boundaries
from keras.models import Model
from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose
from keras.optimizers import Adam, SGD
from keras.callbacks import ModelCheckpoint
from keras import backend as K
from skimage.exposure import rescale_intensity
from keras.callbacks import History
from skimage import io
import segmentation_models as sm

K.set_image_data_format('channels_last')  # TF dimension ordering in this code
smooth = 1.

BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)

"""###Loading images and labels"""

#Resizing images 
SIZE_X = 128 #height  
SIZE_Y = 128  #width 

#Capture training images

train_images = []

imgTrain=glob.glob("/content/drive/MyDrive/Comuter_Vision/A3/Q3/cityscapes_data/train/*jpg")
imgTrain
for i in imgTrain:
    img = cv2.imread(i) 
    #print("dd")
    img = img[:256,:256]      
    img = cv2.resize(img, (SIZE_Y, SIZE_X))
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        #cv2_imshow(img)
        #input()
    train_images.append(img)
        #train_labels.append(label) 
#Convert list to array for machine learning processing        
train_images = np.array(train_images)

print(train_images.shape)
cv2_imshow(train_images[0])

#Capture mask/label info as a list
train_masks = [] 


imgTrain=glob.glob("/content/drive/MyDrive/Comuter_Vision/A3/Q3/cityscapes_data/train/*jpg")
imgTrain
for i in imgTrain:
    mask = cv2.imread(i)  
    mask= mask[:256,256:]   
    #cv2_imshow(mask)  
        #input()
    mask = cv2.resize(mask, (SIZE_Y, SIZE_X))
    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)
    train_masks.append(mask)
   
train_masks = np.array(train_masks)

print(train_masks.shape)
cv2_imshow(train_masks[0])

val_images = []
valpath=glob.glob("/content/drive/MyDrive/Comuter_Vision/A3/Q3/cityscapes_data/val/*jpg")
for i in valpath :
    #for img_path in glob.glob(os.path.join(directory_path, "*.jpg")):
        #print(img_path)
        
    img = cv2.imread(i) 
    img = img[:256,:256]      
        #img = cv2.resize(img, (SIZE_Y, SIZE_X))
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    val_images.append(img)
        #train_labels.append(label) 
#Convert list to array for machine learning processing        
val_images = np.array(val_images)

val_images.shape

#Capture mask/label info as a list
val_masks = [] 
valpath=glob.glob("/content/drive/MyDrive/Comuter_Vision/A3/Q3/cityscapes_data/val/*jpg")
for i in valpath :
    #for mask_path in glob.glob(os.path.join(directory_path, "*.jpg")):
    mask = cv2.imread(i)  
    mask = img[:256,256:]     
        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X))
        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)
    val_masks.append(mask)
        #train_labels.append(label)
#Convert list to array for machine learning processing          
val_masks = np.array(val_masks)

val_masks.shape

"""Splitting the dataset into training and test"""

X = train_images
Y = train_masks
Y = np.expand_dims(Y,axis = 3)

x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# preprocess input
x_train = preprocess_input(x_train)
x_val = preprocess_input(x_val)

#from data import load_train_data, load_test_data



"""Defining the model"""

model = sm.Unet(BACKBONE, encoder_weights='imagenet')
model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score],)
print(model.summary())

history=model.fit(x=x_train,y=y_train,batch_size=32,epochs=100,verbose=1,validation_data=(x_val, y_val),)

#model.save('/content/drive/MyDrive/nails_segmentation/membrane3000.h5')

#model = keras.models.load_model('/content/drive/MyDrive/nails_segmentation/membrane3000.h5', compile=False)

"""Loading a test image"""

test_img = cv2.imread('/content/drive/MyDrive/Comuter_Vision/A3/Q4/nails_segmentation/images/1eecab90-1a92-43a7-b952-0204384e1fae.jpg', cv2.IMREAD_COLOR)       

test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))
test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)
plt.imshow(test_img, cmap='gray')
test_img = np.expand_dims(test_img, axis=0)

prediction = model.predict(test_img)

plt.plot(history.history['iou_score'],'*',c='g',)
#plt.plot(history.history['valsm.metrics.iou_score'])
plt.title('Jaccard Similarity Score Vs Epoch')
plt.ylabel('Jaccard Similarity')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
    #plotting our dice coeff results in function of the number of epochs

"""Segmented Image"""

prediction_image = prediction.reshape(label.shape)
plt.imshow(prediction_image, cmap='gray')

#plt.plot(history.history['iou_score'])
plt.plot(history.history['loss'])
plt.title('Model Loss')
plt.ylabel('Dice coeff')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
    #plotting our dice coeff results in function of the number of epochs

"""#Question 4"""

from __future__ import print_function

import os
from skimage.transform import resize
from skimage.io import imsave
import numpy as np
from skimage.segmentation import mark_boundaries
from keras.models import Model
from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose
from keras.optimizers import Adam, SGD
from keras.callbacks import ModelCheckpoint
from keras import backend as K
from skimage.exposure import rescale_intensity
from keras.callbacks import History
from skimage import io
#from data import load_train_data, load_test_data

K.set_image_data_format('channels_last')  # TF dimension ordering in this code
smooth = 1.

!pip install segmentation-models
!pip install tensorflow==2.1.0
!pip install keras==2.3.1



import glob
import cv2
import os
import numpy as np
from matplotlib import pyplot as plt

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
import segmentation_models as sm

BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)

"""Loading images and labels"""

#Resizing images 
SIZE_X = 128 #height  
SIZE_Y = 128  #width 

#Capture training images
train_images = []

for directory_path in glob.glob("/content/drive/MyDrive/Comuter_Vision/A3/Q4/nails_segmentation/images/"):
    for img_path in glob.glob(os.path.join(directory_path, "*.jpg")):
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       
        img = cv2.resize(img, (SIZE_Y, SIZE_X))
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        train_images.append(img)
        
train_images = np.array(train_images)


#Capture labels
train_masks = [] 
for directory_path in glob.glob("/content/drive/MyDrive/Comuter_Vision/A3/Q4/nails_segmentation/labels/"):
    for label_path in glob.glob(os.path.join(directory_path, "*.jpg")):
        label = cv2.imread(label_path, 0)       
        label = cv2.resize(label, (SIZE_Y, SIZE_X))
        train_masks.append(label)
         
train_masks = np.array(train_masks)

"""Splitting the dataset into training and test"""

X = train_images
Y = train_masks
Y = np.expand_dims(Y,axis = 3)

x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# preprocess input
x_train = preprocess_input(x_train)
x_val = preprocess_input(x_val)



def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

#The functions return our metric and loss

"""Defining the model"""

model = sm.Unet(BACKBONE, encoder_weights='imagenet')
model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score,dice_coef],)
print(model.summary())

history=model.fit(x=x_train,y=y_train,batch_size=32,epochs=100,verbose=1,validation_data=(x_val, y_val),)

#model.save('/content/drive/MyDrive/nails_segmentation/membrane3000.h5')

#model = keras.models.load_model('/content/drive/MyDrive/nails_segmentation/membrane3000.h5', compile=False)

"""Loading a test image"""

test_img = cv2.imread('/content/drive/MyDrive/Comuter_Vision/A3/Q4/nails_segmentation/images/09aefeec-e05f-11e8-87a6-0242ac1c0002.jpg', cv2.IMREAD_COLOR)       

test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))
test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)
plt.imshow(test_img, cmap='gray')
test_img = np.expand_dims(test_img, axis=0)

prediction = model.predict(test_img)

"""Segmented Image"""

prediction_image = prediction.reshape(label.shape)
plt.imshow(prediction_image, cmap='gray')

plt.plot(history.history['dice_coef'], c='g')
#plt.plot(history.history['loss'])
plt.title('Model dice coeff')
plt.ylabel('Dice coeff')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
    #plotting our dice coeff results in function of the number of epochs

#plt.plot(history.history['iou_score'])
plt.plot(history.history['loss'])
plt.title('Model Loss')
plt.ylabel('Dice coeff')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
    #plotting our dice coeff results in function of the number of epochs

plt.plot(history.history['iou_score'],c='r')
#plt.plot(history.history['valsm.metrics.iou_score'])
plt.title('Model IOU coeff')
plt.ylabel('IOU coeff')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
    #plotting our dice coeff results in function of the number of epochs